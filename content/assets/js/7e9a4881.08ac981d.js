"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[6487],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return u}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},k={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=p(n),u=r,m=d["".concat(l,".").concat(u)]||d[u]||k[u]||o;return n?a.createElement(m,i(i({ref:t},c),{},{components:n})):a.createElement(m,i({ref:t},c))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var p=2;p<o;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},6080:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return p},toc:function(){return c},default:function(){return d}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),i=["components"],s={sidebar_position:1},l="Dynamic Fork",p={unversionedId:"reference-docs/dynamic-fork-task",id:"reference-docs/dynamic-fork-task",isDocsHomePage:!1,title:"Dynamic Fork",description:"`json",source:"@site/docs/reference-docs/dynamic-fork-task.md",sourceDirName:"reference-docs",slug:"/reference-docs/dynamic-fork-task",permalink:"/content/docs/reference-docs/dynamic-fork-task",editUrl:"https://github.com/orkes-io/docs/edit/main/docs/reference-docs/dynamic-fork-task.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"referenceDocsSideBar",previous:{title:"Fork",permalink:"/content/docs/reference-docs/fork-task"},next:{title:"Join",permalink:"/content/docs/reference-docs/join-task"}},c=[{value:"Introduction",id:"introduction",children:[]},{value:"Use Cases",id:"use-cases",children:[]},{value:"Configuration",id:"configuration",children:[]}],k={toc:c};function d(e){var t=e.components,n=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},k,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"dynamic-fork"},"Dynamic Fork"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'"type" : "FORK_JOIN_DYNAMIC"\n')),(0,o.kt)("h3",{id:"introduction"},"Introduction"),(0,o.kt)("p",null,"A Fork operation in conductor, lets you run a specified list of other tasks or sub workflows in parallel after the fork\ntask. A fork task is followed by a join operation that waits on the forked tasks or sub workflows to finish. The ",(0,o.kt)("inlineCode",{parentName:"p"},"JOIN"),"\ntask also collects outputs from each of the forked tasks or sub workflows."),(0,o.kt)("p",null,"In a regular fork operation (",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN")," task), the list of tasks or sub workflows that need to be forked and run in\nparallel are already known at the time of workflow definition creation time. However, there are cases when that list can\nonly be determined at run-time and that is when the dynamic fork operation (FORK_JOIN_DYNAMIC task) is needed."),(0,o.kt)("p",null,"There are three things that are needed to configure a ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," task."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"A list of tasks or sub-workflows that needs to be forked and run in parallel."),(0,o.kt)("li",{parentName:"ol"},"A list of inputs to each of these forked tasks or sub-workflows"),(0,o.kt)("li",{parentName:"ol"},"A task prior to the ",(0,o.kt)("inlineCode",{parentName:"li"},"FORK_JOIN_DYNAMIC")," tasks outputs 1 and 2 above that can be wired in as in input to\nthe ",(0,o.kt)("inlineCode",{parentName:"li"},"FORK_JOIN_DYNAMIC")," tasks")),(0,o.kt)("h3",{id:"use-cases"},"Use Cases"),(0,o.kt)("p",null,"A ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," is useful, when a set of tasks or sub-workflows needs to be executed and the number of tasks or\nsub-workflows are determined at run time. E.g. Let's say we have a task that resizes an image, and we need to create a\nworkflow that will resize an image into multiple sizes. In this case, a task can be created prior to\nthe ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," task that will prepare the input that needs to be passed into the ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," task. The\nsingle image resize task does one job. The ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," and the following ",(0,o.kt)("inlineCode",{parentName:"p"},"JOIN")," will manage the multiple\ninvokes of the single image resize task. Here, the responsibilities are clearly broken out, where the single image resize\ntask does the core job and ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," manages the orchestration and fault tolerance aspects."),(0,o.kt)("h3",{id:"configuration"},"Configuration"),(0,o.kt)("p",null,"Here is an example of a ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," task followed by a ",(0,o.kt)("inlineCode",{parentName:"p"},"JOIN")," task"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "inputParameters": {\n    "dynamicTasks": "${fooBarTask.output.dynamicTasksJSON}",\n    "dynamicTasksInput": "${fooBarTask.output.dynamicTasksInputJSON}"\n  },\n  "type": "FORK_JOIN_DYNAMIC",\n  "dynamicForkTasksParam": "dynamicTasks",\n  "dynamicForkTasksInputParamName": "dynamicTasksInput"\n},\n{\n"name": "image_multiple_convert_resize_join",\n"taskReferenceName": "image_multiple_convert_resize_join_ref",\n"type": "JOIN"\n}\n')),(0,o.kt)("p",null,"Dissecting into this example above, let's look at the three things that are needed to configured for\nthe ",(0,o.kt)("inlineCode",{parentName:"p"},"FORK_JOIN_DYNAMIC")," task"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"dynamicForkTasksParam")," This is a JSON array of task or sub-workflow objects that specifies the list of tasks or\nsub-workflows that needs to be forked and run in parallel ",(0,o.kt)("inlineCode",{parentName:"p"},"dynamicForkTasksInputParamName")," This is a JSON map of task or\nsub-workflow objects that specifies the list of tasks or sub-workflows that needs to be forked and run in parallel\nfooBarTask This is a task that is defined prior to the FORK_JOIN_DYNAMIC in the workflow definition. This task will need\nto output (outputParameters) 1 and 2 above so that it can be wired into inputParameters of the FORK_JOIN_DYNAMIC\ntasks. (dynamicTasks and dynamicTasksInput)"),(0,o.kt)("h4",{id:"input-configuration"},"Input Configuration"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Attribute"),(0,o.kt)("th",{parentName:"tr",align:null},"Description"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"name"),(0,o.kt)("td",{parentName:"tr",align:null},"Task Name. A unique name that is descriptive of the task function")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"taskReferenceName"),(0,o.kt)("td",{parentName:"tr",align:null},"Task Reference Name. A unique reference to this task. There can be multiple references of a task within the same workflow definition")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"type"),(0,o.kt)("td",{parentName:"tr",align:null},"Task Type. In this case, ",(0,o.kt)("inlineCode",{parentName:"td"},"FORK_JOIN_DYNAMIC"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"inputParameters"),(0,o.kt)("td",{parentName:"tr",align:null},"The input parameters that will be supplied to this task.")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"dynamicForkTasksParam"),(0,o.kt)("td",{parentName:"tr",align:null},"This is a JSON array of tasks or sub-workflow objects that needs to be forked and run in parallel")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"dynamicForkTasksInputParamName"),(0,o.kt)("td",{parentName:"tr",align:null},"A JSON map, where the keys are task or sub-workflow names, and the values are its corresponding inputParameters")))))}d.isMDXComponent=!0}}]);